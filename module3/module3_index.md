## Module 3: data analysis and machine learning

[[Back to main page]](../index.md)

### Lectures
- day 1 - [Machine Learning Trends – Generative Adversarial
Networks (GANs)](pdf_lectures/day1_talk1_2-GANS-ML-Trends-Generative-Adversarial-Networks.pdf)
    - *Supervised and unsupervised learning - Density estimation - Prescribed models - Latent variable models - Generative Adversarial Networks (GANs)*
- day 1 - [GANs - Implicit Generative Modeling for Password
Estimation](pdf_lectures/day1_talk1_2-GANS-Passwords-Implicit-Generative-Modeling-for-Password-Estimation.pdf)
    -  *PassGANs*
- day 1 - [Machine learning and deep learning](pdf_lectures/day1_talk2_3-Lecture-1_MLandDL.pdf)
    -  *Machine learning review: linear regression - overfitting and underfitting - loss function - risks - estimation vs. approximation - bias and variance - regularization - training, validation and test - supervised learning - unsupervised learning*
- day 2 - [Deep feedforward networks - introduction](pdf_lectures/day2_lecture1_3-Lecture-2-Deep_Feedforward_Networks.pdf)
    -  *Basic building blocks of neural networks (definition, design, training): cost function and output units - network design - optimization*
- day 3 - [Deep feedforward networks - regularization and optimization / Convolutional Neural Networks (CNNs)](pdf_lectures/day3_Lecture-3_Deep-Feedforward-Networks-Regularization.pdf)
    - *Regularization in feedforward neural networks: parameters - optimization - dataset augmentation - I/O noise - semi-supervised learning - early stopping*
    - *Optimization in feedforward neural networks: batch and mini-batch algorithms - stochastic gradient descent - weight initialization*
    - *CNNs: convolutions (standard, unshared, tiled) - stride - padding - pooling*
- day 4 - [Deep unsupervised learning / Generative Adversarial Networks (GANs) / Self-supervised learning / Deep Recurrent Neural etworks (RNNs)](pdf_lectures/day4_3-Lecture-4_Deep-Unsupervised-Learning.pdf)
    - *Deep unsupervised learning: autoencoders - generative models (variational autoencoders)*
    - *GANs: generative modeling - principles of adversarial Learning - issues: vanishing gradient and mode collapse*
    - *Self-supervised learning: principles - overview of the literature - recent developments - transfer learning*
    - *Deep RNNs and sequence Modeling*

 
### Tutorials (juypter notebooks)
- day 1 - tutorial 1: ([jupyter notebook](tutorials/TutorialI.ipynb), [pdf](tutorials/TutorialI.pdf))
    -  *Introduction to TensorFlow*
- day 1 - tutorial 2: ([jupyter notebook](tutorials/TutorialII.ipynb), [pdf](tutorials/TutorialII.pdf))
    - *Optimization in TensorFlow - Introduction to neural networks in TensorFlow*
- day 2 - tutorial 3: ([jupyter notebook](tutorials/TutorialIII.ipynb), [pdf](tutorials/TutorialIII.pdf))
    -  *Handwritten digit recognition*
- day 2 - tutorial 4: ([jupyter notebook](tutorials/TutorialIV.ipynb), [pdf](tutorials/TutorialIV.pdf))
    -  *Convolutions - Image recognition with Inception*
- day 3 - tutorial 5: ([jupyter notebook - v1](tutorials/TutorialV.ipynb), [jupyter notebook - v2](tutorials/Tutorial_V_T-V_split_solution.ipynb), [pdf -  v1](tutorials/TutorialV.pdf), [pdf - v2](tutorials/Tutorial_V_T-V_split_solution.pdf))
    - *Deep models - Image classifier using pretrained Inception model*
- day 4 - tutorial 6: ([jupyter notebook](tutorials/TutorialVI.ipynb), [pdf](tutorials/TutorialVI.pdf))
    -  *Recurrent neural networks to predict/generate text sequence*
    
### Other links
- [LeCun's lectures about deep learning at Collège de France](https://www.college-de-france.fr/site/yann-lecun/_audiovideos.htm)
- [Gdrive repository with pdf of LeCun's talks](https://drive.google.com/drive/folders/0BxKBnD5y2M8NUXhZaXBCNXE4QlE)
- [Pattern Recognition and Machine Learning](http://csis.pace.edu/~ctappert/cs855-18fall) course from PACE University
- [Deep learning](https://cs230.stanford.edu) course from Stanford University
- [personal reading notes](my_readings): unordered information retrieved from various web sites (mostly about CNN, RNN, layer output size calculation, Tensorflow implementation and batches)
- [personal project](https://github.com/mariezufferey/CAS_ADS/tree/master/module3/mz_cnn): final notebooks for my project (CNN)

### Some books of interest
- The Elements of Statistical Learning by Hastie et al. (available [online and as pdf](http://www.web.stanford.edu/~hastie/ElemStatLearn))
- Neural networks and deep learning by Michael Nielsen (available [online](http://neuralnetworksanddeeplearning.com) or as a [compiled version](https://github.com/antonvladyka/neuralnetworksanddeeplearning.com.pdf))
- Neural networks and deep Learning by Aggarwal (pdf available [online](https://rd.springer.com/book/10.1007/978-3-319-94463-0); slides for each chapter also available [here](http://www.charuaggarwal.net/neural.htm))
- Deep learning - a practicioner's approach by Patterson and Gibson (can be found online [here](http://csis.pace.edu/~ctappert/cs855-18fall/DeepLearningPractitionersApproach.pdf) or [here](https://github.com/changwookjun/StudyBook/blob/master/DeepLearningBooks/Deep%20Learning%20-%20Josh%20Patterson%20%26%20Adam%20Gibson.pdf)
- Deep learning by Goodfellow et al. (available [online](http://www.deeplearningbook.org) or as a [compiled version](https://github.com/janishar/mit-deep-learning-book-pdf))
- Pattern recognition and machine learning by Bishop (can be found online [here](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf))
- Tensorflow RIP Tutorial (available as [ebook](https://riptutorial.com/ebook/tensorflow))

### Contact
Questions, comments or suggestions ? Don't hesitate to [contact me](mailto:zufferey.marie@bluewin.ch) !

### Varia
Last but most importantly, support the [GRAAL](http://graal-defenseanimale.org) !

